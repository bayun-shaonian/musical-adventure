{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 简答题",
   "id": "900a6e19bb0fa847"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. TensorFlow 是否可以简单替代 NumPy？两者之间的主要区别是什么？\n",
    "\n",
    "2. 使用 `tf.range(10)` 和 `tf.constant(np.arange(10))` 是否会得到相同的结果？\n",
    "\n",
    "3. 可以通过编写函数或继承 `tf.keras.losses.Loss` 来定义自定义损失函数。两种方法分别应该在什么时候使用？\n",
    "\n",
    "4. 可以直接在函数中定义自定义指标或采用 `tf.keras.metrics.Metric` 子类。两种方法分别应该在什么时候使用？\n",
    "\n",
    "5. 什么时候应该自定义层而不是自定义模型？\n",
    "\n",
    "6. 有哪些示例需要编写自定义训练循环？\n",
    "\n",
    "7. 自定义 Keras 组件中可以包含任意 Python 代码，还是必须转换为 TF 函数？\n",
    "\n",
    "8. 如果要将函数转换为 TF 函数，应避免哪些主要模式？\n",
    "\n",
    "9. 何时需要创建动态 Keras 模型？ 如何动态创建Keras模型？为什么不是所有模型都动态化？\n"
   ],
   "id": "f0568883493d9ef7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1：不能简单替代，核心区别在于设计目标和功能：\n",
    "# NumPy：专注于通用数值计算（矩阵运算、线性代数等），运行在 CPU 上，无自动微分、 GPU 加速（需额外库）或计算图功能，适合科学计算和数据预处理。\n",
    "# TensorFlow：深度学习框架，支持 GPU/TPU 加速、自动微分、计算图（静态 / 动态）、分布式训练等，其张量操作与 NumPy 类似，但更侧重机器学习工作流（模型构建、训练、部署）。\n",
    "# TensorFlow 可替代 NumPy 的部分数值计算功能，但前者依赖更多资源，且 NumPy 在非深度学习场景中更轻量高效\n",
    "# 2：数值结果相同\n",
    "# 3：函数式定义：适合简单逻辑（仅依赖y_true和y_pred），如自定义 MSE 变种。\n",
    "# 继承 tf.keras.losses.Loss：适合需要保存状态或复杂逻辑的场景，如依赖外部参数、需要初始化权重、或损失计算涉及中间变量（如对比损失中的正负样本对）\n",
    "# 4：函数式定义：适合简单、无状态的指标（如简单的误差率），直接返回标量结果。\n",
    "# 继承 tf.keras.metrics.Metric：适合有状态的指标（如准确率、AUC），需要累积中间结果（如总样本数、正确预测数）。需重写__init__、update_state、result和reset_states方法，支持分批次更新和 epoch 级汇总。\n",
    "# 5：自定义层：当需要封装可复用的操作单元（含权重或特定计算逻辑）时，如自定义卷积核、注意力机制模块。层是模型的 “积木”，可嵌入到其他模型中。\n",
    "# 自定义模型：当需要定义完整的网络结构（层的组合）时，如一个包含输入层、隐藏层、输出层的分类器。模型是端到端的训练 / 推理单元，支持fit、save等方法。\n",
    "# 6：非标准训练流程；精细控制梯度；自定义学习率调度；多任务训练中动态调整任务权重；与外部组件交互。\n",
    "# 7：若组件运行在Eager Execution模式（默认），简单 Python 代码（如条件判断、循环）可直接运行；\n",
    "# 若需提升效率（如加速训练）或支持模型序列化 / 部署（如 SavedModel），需使用TensorFlow 操作（如tf.cond替代if），并通过@tf.function转换为计算图。\n",
    "# 8：动态控制流依赖张量值：修改外部变量：使用非 TensorFlow 数据结构：调用非 TF 兼容函数：副作用操作：\n",
    "# 9：何时需要：当模型前向传播依赖动态控制流；\n",
    "# 基于条件选择不同分支的网络（如根据输入类别切换子网络）。\n",
    "# 如何创建：通过子类化"
   ],
   "id": "588577e37314b9f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 编程题",
   "id": "9a282b6d9adda052"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. 实现一个执行层归一化的自定义层：\n",
    "    - a. `build()` 方法应定义两个可训练的权重 α 和 β，它们的形状均为 `input_shape[-1:]`，数据类型为 `tf.float32`。α 应该用 1 初始化，而 β 必须用 0 初始化。\n",
    "    - b. `call()` 方法应计算每个实例特征的均值和标准差。为此，可以使用 `tf.nn.moments(inputs, axes=-1, keepdims=True)`，它返回同一实例的均值 μ 和方差 σ²（计算方差的平方根便可获得标准差）。然后，该函数应计算并返回\n",
    "      $$\n",
    "      \\alpha \\otimes \\frac{(X-\\mu)}{(\\sigma+\\epsilon)} + \\beta\n",
    "      $$\n",
    "      其中 ε 是表示项精度的一个常量（避免被零除的小常数，例如 0.001）,$\\otimes$表示逐个元素相乘\n",
    "    - c. 确保自定义层产生与tf.keras.layers.LayerNormalization层相同（或几乎相同）的输出。\n",
    "\n",
    "2. 使用自定义训练循环训练模型来处理Fashion MNIST数据集（13_神经网络介绍 里用的数据集）：\n",
    "\n",
    "    - a.显示每个轮次、迭代、平均训练损失和每个轮次的平均精度（在每次迭代中更新），以及每个轮次结束时的验证损失和精度。\n",
    "    - b.尝试对上面的层和下面的层使用具有不同学习率的不同优化器。"
   ],
   "id": "5cd3d7096f87afd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T02:03:49.825105Z",
     "start_time": "2025-09-15T02:03:39.883092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "class CustomLayerNormalization(Layer):\n",
    "    def __init__(self, epsilon=0.001, **kwargs):\n",
    "        super(CustomLayerNormalization, self).__init__(** kwargs)\n",
    "        self.epsilon = epsilon  # 避免被零除的小常数\n",
    "    def build(self, input_shape):\n",
    "        # 定义可训练的权重α和β，形状为input_shape的最后一个维度\n",
    "        self.alpha = self.add_weight(\n",
    "            name='alpha',\n",
    "            shape=input_shape[-1:],\n",
    "            dtype=tf.float32,\n",
    "            initializer=tf.ones_initializer(),  # α用1初始化\n",
    "            trainable=True)\n",
    "        self.beta = self.add_weight(\n",
    "            name='beta',\n",
    "            shape=input_shape[-1:],\n",
    "            dtype=tf.float32,\n",
    "            initializer=tf.zeros_initializer(),  # β用0初始化\n",
    "            trainable=True)\n",
    "        super(CustomLayerNormalization, self).build(input_shape)  # 确保build方法被正确调用\n",
    "    def call(self, inputs):\n",
    "        # 计算均值和方差\n",
    "        mean, variance = tf.nn.moments(inputs, axes=-1, keepdims=True)\n",
    "        # 计算标准差\n",
    "        stddev = tf.sqrt(variance + self.epsilon)\n",
    "        # 执行层归一化计算：α ⊗ (X-μ)/(σ+ε) + β\n",
    "        normalized = (inputs - mean) / stddev\n",
    "        output = self.alpha * normalized + self.beta  # *表示逐个元素相乘\n",
    "        return output\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # 输出形状与输入形状相同\n",
    "        return input_shape\n",
    "# 测试自定义层与Keras内置层的一致性\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建测试输入\n",
    "    test_input = tf.random.normal(shape=(2, 3, 4))  # 批次大小为2，特征维度为3x4\n",
    "    # 创建自定义层和Keras内置层\n",
    "    custom_ln = CustomLayerNormalization()\n",
    "    keras_ln = tf.keras.layers.LayerNormalization(epsilon=0.001)\n",
    "    # 进行前向传播\n",
    "    custom_output = custom_ln(test_input)\n",
    "    keras_output = keras_ln(test_input)\n",
    "    # 打印输出形状\n",
    "    print(\"输入形状:\", test_input.shape)\n",
    "    print(\"自定义层输出形状:\", custom_output.shape)\n",
    "    print(\"Keras内置层输出形状:\", keras_output.shape)\n",
    "    # 计算两个输出之间的差异\n",
    "    difference = tf.reduce_mean(tf.abs(custom_output - keras_output))\n",
    "    print(\"输出差异（均值绝对值）:\", difference.numpy())\n",
    "    # 如果差异很小，则认为两个层的输出几乎相同\n",
    "    if difference < 1e-5:\n",
    "        print(\"测试通过：自定义层与Keras内置层输出几乎相同\")\n",
    "    else:\n",
    "        print(\"测试失败：自定义层与Keras内置层输出差异较大\")"
   ],
   "id": "4cb9da9f5e9ea249",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入形状: (2, 3, 4)\n",
      "自定义层输出形状: (2, 3, 4)\n",
      "Keras内置层输出形状: (2, 3, 4)\n",
      "输出差异（均值绝对值）: 4.284084e-08\n",
      "测试通过：自定义层与Keras内置层输出几乎相同\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T02:13:03.063602Z",
     "start_time": "2025-09-15T02:11:20.981877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 加载Fashion MNIST数据集\n",
    "(x_train, y_train), (x_val, y_val) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "# 数据预处理\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_val = x_val.astype('float32') / 255.0\n",
    "# 转换为通道维度 (28, 28) -> (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_val = np.expand_dims(x_val, -1)\n",
    "# 转换标签为独热编码\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, 10)\n",
    "# 创建数据集对象\n",
    "batch_size = 32\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(60000).batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "# 定义模型 - 将模型分为两部分，以便使用不同的优化器\n",
    "class LowerLayers(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(LowerLayers, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')\n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        return self.flatten(x)\n",
    "class UpperLayers(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(UpperLayers, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)\n",
    "# 实例化模型部分\n",
    "lower_layers = LowerLayers()\n",
    "upper_layers = UpperLayers()\n",
    "# 为不同层定义不同的优化器 - 下层使用较小的学习率，上层使用较大的学习率\n",
    "lower_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "upper_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "# 损失函数\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "# 评估指标\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "val_accuracy = tf.keras.metrics.CategoricalAccuracy(name='val_accuracy')\n",
    "# 训练步骤\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # 前向传播\n",
    "        features = lower_layers(images)\n",
    "        predictions = upper_layers(features)\n",
    "        loss = loss_fn(labels, predictions)\n",
    "    # 计算梯度\n",
    "    lower_gradients = tape.gradient(loss, lower_layers.trainable_variables)\n",
    "    upper_gradients = tape.gradient(loss, upper_layers.trainable_variables)\n",
    "    # 应用梯度\n",
    "    lower_optimizer.apply_gradients(zip(lower_gradients, lower_layers.trainable_variables))\n",
    "    upper_optimizer.apply_gradients(zip(upper_gradients, upper_layers.trainable_variables))\n",
    "    # 更新指标\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "    # 删除persistent tape\n",
    "    del tape\n",
    "# 验证步骤\n",
    "@tf.function\n",
    "def val_step(images, labels):\n",
    "    features = lower_layers(images)\n",
    "    predictions = upper_layers(features)\n",
    "    v_loss = loss_fn(labels, predictions)\n",
    "    val_loss(v_loss)\n",
    "    val_accuracy(labels, predictions)\n",
    "# 训练模型\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    # 重置训练指标\n",
    "    train_loss = tf.keras.metrics.Mean('train_loss')\n",
    "    train_accuracy = tf.keras.metrics.CategoricalAccuracy('train_accuracy')\n",
    "    # 训练循环\n",
    "    for i, (images, labels) in enumerate(train_dataset):\n",
    "        train_step(images, labels)\n",
    "        # 每100个批次打印一次中间结果\n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch {epoch + 1}, Iteration {i}, '\n",
    "                  f'Train Loss: {train_loss.result():.4f}, '\n",
    "                  f'Train Accuracy: {train_accuracy.result():.4f}')\n",
    "    # 验证循环\n",
    "    for images, labels in val_dataset:\n",
    "        val_step(images, labels)\n",
    "    # 打印每个轮次结束的结果\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    print(f'Train Loss: {train_loss.result():.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy.result():.4f}')\n",
    "    print(f'Val Loss: {val_loss.result():.4f}, '\n",
    "          f'Val Accuracy: {val_accuracy.result():.4f}\\n')\n",
    "# 可视化一些预测结果\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "def plot_predictions():\n",
    "    # 随机选择一些测试图像\n",
    "    num_samples = 5\n",
    "    indices = np.random.choice(len(x_val), num_samples)\n",
    "    sample_images = x_val[indices]\n",
    "    sample_labels = y_val[indices]\n",
    "    # 获取预测结果\n",
    "    features = lower_layers(sample_images)\n",
    "    predictions = upper_layers(features)\n",
    "    predicted_classes = np.argmax(predictions.numpy(), axis=1)\n",
    "    true_classes = np.argmax(sample_labels, axis=1)\n",
    "    # 绘制结果\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(1, num_samples, i + 1)\n",
    "        plt.imshow(sample_images[i].squeeze(), cmap='gray')\n",
    "        plt.title(f\"True: {class_names[true_classes[i]]}\\nPred: {class_names[predicted_classes[i]]}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "# 显示预测结果\n",
    "plot_predictions()"
   ],
   "id": "288e09664847c78c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 0, Train Loss: 2.3069, Train Accuracy: 0.0625\n",
      "Epoch 1, Iteration 100, Train Loss: 1.6146, Train Accuracy: 0.5192\n",
      "Epoch 1, Iteration 200, Train Loss: 1.2258, Train Accuracy: 0.6073\n",
      "Epoch 1, Iteration 300, Train Loss: 1.0508, Train Accuracy: 0.6496\n",
      "Epoch 1, Iteration 400, Train Loss: 0.9522, Train Accuracy: 0.6732\n",
      "Epoch 1, Iteration 500, Train Loss: 0.8866, Train Accuracy: 0.6920\n",
      "Epoch 1, Iteration 600, Train Loss: 0.8397, Train Accuracy: 0.7063\n",
      "Epoch 1, Iteration 700, Train Loss: 0.8058, Train Accuracy: 0.7153\n",
      "Epoch 1, Iteration 800, Train Loss: 0.7776, Train Accuracy: 0.7237\n",
      "Epoch 1, Iteration 900, Train Loss: 0.7513, Train Accuracy: 0.7314\n",
      "Epoch 1, Iteration 1000, Train Loss: 0.7303, Train Accuracy: 0.7389\n",
      "Epoch 1, Iteration 1100, Train Loss: 0.7115, Train Accuracy: 0.7454\n",
      "Epoch 1, Iteration 1200, Train Loss: 0.6962, Train Accuracy: 0.7504\n",
      "Epoch 1, Iteration 1300, Train Loss: 0.6813, Train Accuracy: 0.7554\n",
      "Epoch 1, Iteration 1400, Train Loss: 0.6688, Train Accuracy: 0.7593\n",
      "Epoch 1, Iteration 1500, Train Loss: 0.6585, Train Accuracy: 0.7625\n",
      "Epoch 1, Iteration 1600, Train Loss: 0.6462, Train Accuracy: 0.7666\n",
      "Epoch 1, Iteration 1700, Train Loss: 0.6367, Train Accuracy: 0.7698\n",
      "Epoch 1, Iteration 1800, Train Loss: 0.6272, Train Accuracy: 0.7730\n",
      "Epoch 1/10\n",
      "Train Loss: 0.6215, Train Accuracy: 0.7750\n",
      "Val Loss: 0.4747, Val Accuracy: 0.8260\n",
      "\n",
      "Epoch 2, Iteration 0, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 2, Iteration 100, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 2, Iteration 200, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 2, Iteration 300, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 2, Iteration 400, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 2, Iteration 500, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 2, Iteration 600, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 2, Iteration 700, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 2, Iteration 800, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 2, Iteration 900, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 2, Iteration 1000, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 2, Iteration 1100, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 2, Iteration 1200, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 2, Iteration 1300, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 2, Iteration 1400, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 2, Iteration 1500, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 2, Iteration 1600, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 2, Iteration 1700, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 2, Iteration 1800, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 2/10\n",
      "Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Val Loss: 0.4401, Val Accuracy: 0.8411\n",
      "\n",
      "Epoch 3, Iteration 0, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 3, Iteration 100, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 3, Iteration 200, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 3, Iteration 300, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 3, Iteration 400, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 3, Iteration 500, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 3, Iteration 600, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 3, Iteration 700, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 3, Iteration 800, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 3, Iteration 900, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 3, Iteration 1000, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 3, Iteration 1100, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 3, Iteration 1200, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 3, Iteration 1300, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 3, Iteration 1400, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 3, Iteration 1500, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 3, Iteration 1600, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 3, Iteration 1700, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 3, Iteration 1800, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 3/10\n",
      "Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Val Loss: 0.4109, Val Accuracy: 0.8514\n",
      "\n",
      "Epoch 4, Iteration 0, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 4, Iteration 100, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 4, Iteration 200, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 4, Iteration 300, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 4, Iteration 400, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 4, Iteration 500, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 4, Iteration 600, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 4, Iteration 700, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 4, Iteration 800, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 4, Iteration 900, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 4, Iteration 1000, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 4, Iteration 1100, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 4, Iteration 1200, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 4, Iteration 1300, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 4, Iteration 1400, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 4, Iteration 1500, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 4, Iteration 1600, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 4, Iteration 1700, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 4, Iteration 1800, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 4/10\n",
      "Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Val Loss: 0.3898, Val Accuracy: 0.8589\n",
      "\n",
      "Epoch 5, Iteration 0, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 5, Iteration 100, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 5, Iteration 200, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 5, Iteration 300, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 5, Iteration 400, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 5, Iteration 500, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 5, Iteration 600, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 5, Iteration 700, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 5, Iteration 800, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 5, Iteration 900, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 5, Iteration 1000, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 5, Iteration 1100, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 5, Iteration 1200, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 5, Iteration 1300, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 5, Iteration 1400, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 5, Iteration 1500, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 5, Iteration 1600, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 5, Iteration 1700, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 5, Iteration 1800, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 5/10\n",
      "Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Val Loss: 0.3715, Val Accuracy: 0.8658\n",
      "\n",
      "Epoch 6, Iteration 0, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 6, Iteration 100, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 6, Iteration 200, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 6, Iteration 300, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 6, Iteration 400, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 6, Iteration 500, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 6, Iteration 600, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 6, Iteration 700, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 6, Iteration 800, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 6, Iteration 900, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 6, Iteration 1000, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 6, Iteration 1100, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 6, Iteration 1200, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 6, Iteration 1300, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 6, Iteration 1400, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 6, Iteration 1500, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 6, Iteration 1600, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 6, Iteration 1700, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 6, Iteration 1800, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 6/10\n",
      "Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Val Loss: 0.3586, Val Accuracy: 0.8705\n",
      "\n",
      "Epoch 7, Iteration 0, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 7, Iteration 100, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 7, Iteration 200, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 7, Iteration 300, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 7, Iteration 400, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 7, Iteration 500, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 7, Iteration 600, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 7, Iteration 700, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 7, Iteration 800, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 7, Iteration 900, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 7, Iteration 1000, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 7, Iteration 1100, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 7, Iteration 1200, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 7, Iteration 1300, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 7, Iteration 1400, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 7, Iteration 1500, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 7, Iteration 1600, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 7, Iteration 1700, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 7, Iteration 1800, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 7/10\n",
      "Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Val Loss: 0.3493, Val Accuracy: 0.8738\n",
      "\n",
      "Epoch 8, Iteration 0, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 8, Iteration 100, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 8, Iteration 200, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 8, Iteration 300, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 8, Iteration 400, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 8, Iteration 500, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 8, Iteration 600, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 8, Iteration 700, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 8, Iteration 800, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 8, Iteration 900, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 8, Iteration 1000, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 8, Iteration 1100, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 8, Iteration 1200, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 8, Iteration 1300, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 8, Iteration 1400, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 8, Iteration 1500, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 8, Iteration 1600, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 8, Iteration 1700, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 8, Iteration 1800, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 8/10\n",
      "Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Val Loss: 0.3409, Val Accuracy: 0.8769\n",
      "\n",
      "Epoch 9, Iteration 0, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 9, Iteration 100, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 9, Iteration 200, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 9, Iteration 300, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 9, Iteration 400, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 9, Iteration 500, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 9, Iteration 600, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 9, Iteration 700, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 9, Iteration 800, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 9, Iteration 900, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 9, Iteration 1000, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 9, Iteration 1100, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 9, Iteration 1200, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 9, Iteration 1300, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 9, Iteration 1400, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 9, Iteration 1500, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 9, Iteration 1600, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 9, Iteration 1700, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 9, Iteration 1800, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 9/10\n",
      "Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Val Loss: 0.3357, Val Accuracy: 0.8782\n",
      "\n",
      "Epoch 10, Iteration 0, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 10, Iteration 100, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 10, Iteration 200, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 10, Iteration 300, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 10, Iteration 400, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 10, Iteration 500, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 10, Iteration 600, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 10, Iteration 700, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 10, Iteration 800, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 10, Iteration 900, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 10, Iteration 1000, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 10, Iteration 1100, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 10, Iteration 1200, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 10, Iteration 1300, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 10, Iteration 1400, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 10, Iteration 1500, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 10, Iteration 1600, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 10, Iteration 1700, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 10, Iteration 1800, Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Epoch 10/10\n",
      "Train Loss: 0.0000, Train Accuracy: 0.0000\n",
      "Val Loss: 0.3295, Val Accuracy: 0.8805\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 5 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
